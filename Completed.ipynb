{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm6I_g1XfslG"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBC58eSGsHNz",
        "outputId": "e00a97d8-60fb-4273-c17c-2f17bf8a3e42"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUqH3d5_fBqg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization as bn\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.models import model_from_json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmIfKG5LdC_t"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbP44aVqGs5C",
        "outputId": "83107019-af15-496c-89bf-3c6b77c338ed"
      },
      "outputs": [],
      "source": [
        "!pip install nibabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJAD-VrYfFki"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_S0xiVasy7P",
        "outputId": "70454f1c-f37c-4253-86d0-88679749155f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT8U_w0atOWT",
        "outputId": "2c63470d-bf7a-4910-d923-b280d3a550f8"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/My Drive/Dataset/Train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97eVJW7sr7Ha"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO2ZZSu6fPmW",
        "outputId": "bd89cbd3-3e39-4ec0-a550-0394f614030d"
      },
      "outputs": [],
      "source": [
        "img_path = glob(\"volume-*.nii\")\n",
        "mask_path = glob(\"segmentation-*.nii\")\n",
        "\n",
        "print(\"Number of images :\", len(img_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sx-vRcrIyNmn",
        "outputId": "08fb8742-1ad3-4f87-bac4-1d187f266894"
      },
      "outputs": [],
      "source": [
        "img_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UJoMBveXlc1"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text\n",
        "\n",
        "def natural_keys(text):\n",
        "    '''\n",
        "    alist.sort(key=natural_keys) sorts in human order\n",
        "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
        "    (See Toothy's implementation in the comments)\n",
        "    '''\n",
        "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQiTREr-Ydea"
      },
      "outputs": [],
      "source": [
        "img_path.sort(key=natural_keys)\n",
        "mask_path.sort(key=natural_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OoeQZ7X6x8g"
      },
      "outputs": [],
      "source": [
        "# img_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz392SQ8fviu"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwoYHpUkDe1d"
      },
      "outputs": [],
      "source": [
        "def normalize_hu(volume, clip_min=-100, clip_max=400):\n",
        "    volume = np.clip(volume, clip_min, clip_max)\n",
        "    return (volume - clip_min) / (clip_max - clip_min)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0SWnFyjIz5h"
      },
      "outputs": [],
      "source": [
        "patch_ratio = []\n",
        "\n",
        "for i in range(16 + 1):\n",
        "  patch_ratio.append(32 * i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C88ATIWmdFA8",
        "outputId": "31aebf8e-3784-46fe-e346-1a1e36fb3cf5"
      },
      "outputs": [],
      "source": [
        "patch_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGiIGSjmfvqt"
      },
      "outputs": [],
      "source": [
        "def patch_sampling(img, mask, patch_ratio, pos_neg_ratio, threshold):\n",
        "\n",
        "  temp_mask = mask\n",
        "\n",
        "  temp_mask[temp_mask == 1] = 0\n",
        "  temp_mask[temp_mask == 2] = 1\n",
        "\n",
        "  positive_patch = []\n",
        "  positive_mask = []\n",
        "\n",
        "  negative_patch = []\n",
        "  negative_mask = []\n",
        "\n",
        "  negative_set = []\n",
        "\n",
        "\n",
        "  for i in range(temp_mask.shape[2]):\n",
        "    for x_bin in range(2, len(patch_ratio)):\n",
        "        for y_bin in range(2, len(patch_ratio)):\n",
        "          img_patch = img[patch_ratio[x_bin-2] : patch_ratio[x_bin], patch_ratio[y_bin - 2] : patch_ratio[y_bin], i]\n",
        "          mask_patch = temp_mask[patch_ratio[x_bin-2] : patch_ratio[x_bin], patch_ratio[y_bin - 2] : patch_ratio[y_bin], i]\n",
        "          _, count = np.unique(mask_patch, return_counts = True)\n",
        "\n",
        "          if len(count) == 2:\n",
        "            mask_percentage = count[1] / sum(count) * 100\n",
        "\n",
        "            if threshold < mask_percentage :\n",
        "              positive_patch.append(img_patch)\n",
        "              positive_mask.append(mask_patch)\n",
        "\n",
        "\n",
        "          elif len(count) ==1:\n",
        "\n",
        "            temp_list = []\n",
        "            temp_list.append(img_patch)\n",
        "            temp_list.append(mask_patch)\n",
        "\n",
        "            negative_set.append(temp_list)\n",
        "\n",
        "  shuffle(negative_set)\n",
        "\n",
        "  negative_set_to_use = negative_set[:len(positive_patch) * pos_neg_ratio]\n",
        "  for negative_set in negative_set_to_use:\n",
        "    negative_patch.append(negative_set[0])\n",
        "    negative_mask.append(negative_set[1])\n",
        "\n",
        "  negative_set_to_use = []\n",
        "\n",
        "  return positive_patch, positive_mask, negative_patch, negative_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngq1ZUab3F6r"
      },
      "outputs": [],
      "source": [
        "def slice_to_patch(slice, patch_ratio):\n",
        "\n",
        "  slice[slice == 1] = 0\n",
        "  slice[slice == 2] = 1\n",
        "\n",
        "  patch_list = []\n",
        "\n",
        "  for x_bin in range(2, len(patch_ratio)):\n",
        "    for y_bin in range(2, len(patch_ratio)):\n",
        "      patch = slice[patch_ratio[x_bin-2] : patch_ratio[x_bin], patch_ratio[y_bin - 2] : patch_ratio[y_bin]]\n",
        "      patch = patch.reshape(patch.shape + (1,))\n",
        "      patch_list.append(patch)\n",
        "\n",
        "  return np.array(patch_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsbWGHyE6nXh"
      },
      "outputs": [],
      "source": [
        "def patch_to_slice(patch, patch_ratio, input_shape, conf_threshold):\n",
        "\n",
        "  slice = np.zeros((512, 512, 1))\n",
        "  row_idx = 0\n",
        "  col_idx = 0\n",
        "\n",
        "  for i in range(len(patch)):\n",
        "\n",
        "    slice[patch_ratio[row_idx]:patch_ratio[row_idx + 2], patch_ratio[col_idx]:patch_ratio[col_idx + 2]][patch[i] > conf_threshold] = 1\n",
        "\n",
        "    col_idx += 1\n",
        "\n",
        "    if i != 0 and (i+1) % 15 == 0:\n",
        "      row_idx += 1\n",
        "      col_idx = 0\n",
        "\n",
        "  return slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5H1bN8MdLoH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pde5eS9EeX1C"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "from keras.saving import register_keras_serializable\n",
        "\n",
        "@register_keras_serializable()\n",
        "def weighted_binary_crossentropy(y_true, y_pred):\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "    pos_weight = 0.90\n",
        "    neg_weight = 0.10\n",
        "    loss = - (y_true * K.log(y_pred) * pos_weight + (1 - y_true) * K.log(1 - y_pred) * neg_weight)\n",
        "    return K.mean(loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tp9RVRHwrxhc"
      },
      "outputs": [],
      "source": [
        "# Reference : https://github.com/dk67604/LITS-Challenge-Liver-Segmentation/blob/master/experiments/keras_realtime_train.ipynb\n",
        "\n",
        "smooth = 1.\n",
        "@register_keras_serializable()\n",
        "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-KnEpEjfYbO"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvwhakozfY87"
      },
      "outputs": [],
      "source": [
        "# input_shape = [64, 64, 1]\n",
        "# dropout_rate = 0.3\n",
        "# l2_lambda = 0.0002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPW2F07zfZGr"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4-GIhQbr48Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDG0ni4kfaRv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRlumUgWuHMf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD3-TbOvoPf2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX4llXxL1IFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdFnLUNEoFAi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout, Dense, LayerNormalization, Reshape, MultiHeadAttention, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.utils import register_keras_serializable\n",
        "\n",
        "\n",
        "@register_keras_serializable()\n",
        "class PatchExtractor(Layer):\n",
        "    def __init__(self, patch_size,**kwargs):\n",
        "        super(PatchExtractor, self).__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=inputs,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"patch_size\": self.patch_size\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, num_heads, projection_dim, dropout_rate=0.1,**kwargs):\n",
        "        super(TransformerBlock, self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = projection_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.mha = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim // num_heads, dropout=0.0\n",
        "        )\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dense1 = Dense(projection_dim * 2, activation=tf.nn.gelu)\n",
        "        self.dense2 = Dense(projection_dim)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.layernorm1(inputs)\n",
        "        attention_output = self.mha(x, x)\n",
        "        x1 = attention_output + inputs\n",
        "\n",
        "        x2 = self.layernorm2(x1)\n",
        "        x3 = self.dense1(x2)\n",
        "        x3 = self.dropout1(x3, training=training)\n",
        "        x3 = self.dense2(x3)\n",
        "        x3 = self.dropout2(x3, training=training)\n",
        "\n",
        "        return x1 + x3\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"projection_dim\": self.projection_dim,\n",
        "            \"dropout_rate\": self.dropout_rate\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(Layer):\n",
        "    def __init__(self, sequence_length, projection_dim,**kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.projection_dim = projection_dim\n",
        "        self.position_embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        positions = tf.range(start=0, limit=self.sequence_length, delta=1)\n",
        "        embedded_positions = self.position_embedding(positions)\n",
        "        return inputs + embedded_positions\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"projection_dim\": self.projection_dim\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class ReshapeToSpatial(Layer):\n",
        "    def __init__(self, height, width, patch_size, channels,**kwargs):\n",
        "        super(ReshapeToSpatial, self).__init__(**kwargs)\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.patch_size = patch_size\n",
        "        self.channels = channels\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Calculate dimensions\n",
        "        h_dim = self.height // self.patch_size\n",
        "        w_dim = self.width // self.patch_size\n",
        "\n",
        "        # Reshape to spatial dimensions\n",
        "        x = tf.reshape(inputs, [-1, h_dim, w_dim, self.patch_size * self.patch_size * self.channels])\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"height\": self.height,\n",
        "            \"width\": self.width,\n",
        "            \"patch_size\": self.patch_size,\n",
        "            \"channels\": self.channels\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class PatchProjection(Layer):\n",
        "    def __init__(self, projection_dim, l2_lambda=0.0002,**kwargs):\n",
        "        super(PatchProjection, self).__init__(**kwargs)\n",
        "        self.projection_dim = projection_dim\n",
        "        self.l2_lambda = l2_lambda\n",
        "        self.projection = Dense(\n",
        "            units=projection_dim,\n",
        "            kernel_regularizer=regularizers.l2(l2_lambda)\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.projection(inputs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"projection_dim\": self.projection_dim,\n",
        "            \"l2_lambda\": self.l2_lambda\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "def TransUNet(input_shape=(64, 64, 1), dropout_rate=0.3, l2_lambda=0.0002,\n",
        "              projection_dim=64, transformer_layers=4, num_heads=4):\n",
        "    inputs = Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "    # === Encoder (same depth as U-Net) ===\n",
        "    conv1 = Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(inputs)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D()(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Conv2D(64, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D()(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Conv2D(128, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D()(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Conv2D(256, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    pool4 = MaxPooling2D()(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(pool4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Conv2D(512, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2_lambda))(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    pool5 = MaxPooling2D()(conv5)  # (2, 2, 512)\n",
        "\n",
        "    # === Bottleneck with Vision Transformer ===\n",
        "    patch_size = 1  # Since pool5 is already 2x2, use 1x1 patches\n",
        "    num_patches = (2 // patch_size) ** 2  # 4 patches\n",
        "    feature_dim = pool5.shape[-1]\n",
        "\n",
        "    # Extract patches\n",
        "    patches = PatchExtractor(patch_size=patch_size)(pool5)\n",
        "\n",
        "    # Project patches to the transformer dimension\n",
        "    projected_patches = PatchProjection(projection_dim=projection_dim, l2_lambda=l2_lambda)(patches)\n",
        "\n",
        "    # Add positional embeddings\n",
        "    x = PositionalEmbedding(sequence_length=num_patches, projection_dim=projection_dim)(projected_patches)\n",
        "\n",
        "    # Apply transformer blocks\n",
        "    for i in range(transformer_layers):\n",
        "        x = TransformerBlock(\n",
        "            num_heads=num_heads,\n",
        "            projection_dim=projection_dim,\n",
        "            dropout_rate=dropout_rate\n",
        "        )(x, training=True)\n",
        "\n",
        "    # Reshape back to spatial dimensions for the decoder\n",
        "    x = Reshape((2, 2, projection_dim))(x)\n",
        "\n",
        "    # === Decoder ===\n",
        "    up6 = Conv2DTranspose(512, 3, strides=2, padding='same')(x)  # 4x4\n",
        "    up6 = concatenate([up6, conv5])\n",
        "    up6 = Conv2D(512, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up6)\n",
        "    up6 = BatchNormalization()(up6)\n",
        "    up6 = Conv2D(512, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up6)\n",
        "    up6 = BatchNormalization()(up6)\n",
        "\n",
        "    up7 = Conv2DTranspose(256, 3, strides=2, padding='same')(up6)  # 8x8\n",
        "    up7 = concatenate([up7, conv4])\n",
        "    up7 = Conv2D(256, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up7)\n",
        "    up7 = BatchNormalization()(up7)\n",
        "    up7 = Conv2D(256, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up7)\n",
        "    up7 = BatchNormalization()(up7)\n",
        "\n",
        "    up8 = Conv2DTranspose(128, 3, strides=2, padding='same')(up7)  # 16x16\n",
        "    up8 = concatenate([up8, conv3])\n",
        "    up8 = Conv2D(128, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up8)\n",
        "    up8 = BatchNormalization()(up8)\n",
        "    up8 = Conv2D(128, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up8)\n",
        "    up8 = BatchNormalization()(up8)\n",
        "\n",
        "    up9 = Conv2DTranspose(64, 3, strides=2, padding='same')(up8)  # 32x32\n",
        "    up9 = concatenate([up9, conv2])\n",
        "    up9 = Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up9)\n",
        "    up9 = BatchNormalization()(up9)\n",
        "    up9 = Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up9)\n",
        "    up9 = BatchNormalization()(up9)\n",
        "\n",
        "    up10 = Conv2DTranspose(32, 3, strides=2, padding='same')(up9)  # 64x64\n",
        "    up10 = concatenate([up10, conv1])\n",
        "    up10 = Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up10)\n",
        "    up10 = BatchNormalization()(up10)\n",
        "    up10 = Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(up10)\n",
        "    up10 = BatchNormalization()(up10)\n",
        "\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(up10)\n",
        "\n",
        "    return Model(inputs, outputs, name=\"TransUNet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvN8rlXQuIwb"
      },
      "outputs": [],
      "source": [
        "input_shape = [64, 64, 1]\n",
        "dropout_rate = 0.3\n",
        "l2_lambda = 0.0002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5MI-OZnpsiL"
      },
      "outputs": [],
      "source": [
        "model = TransUNet(input_shape=input_shape, dropout_rate=dropout_rate, l2_lambda=l2_lambda)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ev26fndqfb0Z",
        "outputId": "7db1d0ed-33f1-461b-f808-09356c3ae123"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDdZ5ZI0uTS2",
        "outputId": "45ba60d3-2207-48fe-f645-fe4618ae52c8"
      },
      "outputs": [],
      "source": [
        "!pip install pydot pydotplus graphviz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "8K2PTGT6zLPJ",
        "outputId": "d5f822f4-f401-4184-8995-ee08728f6710"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file='model7.png',\n",
        "    show_shapes=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir='TB',\n",
        "    expand_nested=False,\n",
        "    dpi=96\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLgPTCbHuS5m"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyy5fU_TdNAC"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTGOjBUcrxh4"
      },
      "source": [
        "__Data__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vXNvKMlrxh5"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VLDkxAigXPHf",
        "outputId": "144a8380-948d-4cb9-fd37-66731eb334a7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "save_dir = \"/content/patches/\"  # Absolute path in Colab\n",
        "os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "for i in range(len(img_path) - 80):\n",
        "    img_3D = nib.load(img_path[i]).get_fdata()\n",
        "    mask_3D = nib.load(mask_path[i]).get_fdata()\n",
        "\n",
        "    pos_patch, pos_mask, neg_patch, neg_mask = patch_sampling(img_3D, mask_3D, patch_ratio, 3, 3.0)\n",
        "\n",
        "    # Save patches to disk\n",
        "    np.save(os.path.join(save_dir, f\"img_patches_{i}.npy\"), np.array(pos_patch + neg_patch))\n",
        "    np.save(os.path.join(save_dir, f\"mask_patches_{i}.npy\"), np.array(pos_mask + neg_mask))\n",
        "\n",
        "    print(f\"Step [{i+1}/{len(img_path)}] : Patches saved to disk\")\n",
        "\n",
        "print(\"Processing complete! All patches are saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfUXex8mDzYf",
        "outputId": "6120b23e-4d12-439f-9122-771b38d3fe65"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "patch_ratio = [32 * i for i in range(17)]\n",
        "save_dir = \"/content/patches_tumor_only\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "img_path = sorted(glob(\"volume-*.nii\"), key=natural_keys)\n",
        "mask_path = sorted(glob(\"segmentation-*.nii\"), key=natural_keys)\n",
        "\n",
        "for i in range(len(img_path)-30):\n",
        "    img_3D = normalize_hu(nib.load(img_path[i]).get_fdata())\n",
        "    mask_3D = nib.load(mask_path[i]).get_fdata()\n",
        "\n",
        "    pos_patch, pos_mask, neg_patch, neg_mask = patch_sampling_tumor_inside_liver(\n",
        "        img_3D, mask_3D, patch_ratio, pos_neg_ratio=3, threshold=3.0\n",
        "    )\n",
        "\n",
        "    np.save(os.path.join(save_dir, f\"img_patches_{i}.npy\"), np.array(pos_patch + neg_patch))\n",
        "    np.save(os.path.join(save_dir, f\"mask_patches_{i}.npy\"), np.array(pos_mask + neg_mask))\n",
        "\n",
        "    print(f\"✓ Saved patches for volume {i}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcToJGBmEmSo",
        "outputId": "51ba7057-d732-4277-98f0-dc7191e1f0ee"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "# save_dir = \"/content/patches_tumor_only\"  # or \"/content/patches_tumor_only\" if following Option 1\n",
        "\n",
        "# # Gather all valid patch files\n",
        "# img_files = sorted([f for f in os.listdir(save_dir) if f.startswith(\"img_patches_\")])\n",
        "# mask_files = sorted([f for f in os.listdir(save_dir) if f.startswith(\"mask_patches_\")])\n",
        "\n",
        "# X, Y = [], []\n",
        "\n",
        "# for img_f, mask_f in zip(img_files, mask_files):\n",
        "#     x = np.load(os.path.join(save_dir, img_f))\n",
        "#     y = np.load(os.path.join(save_dir, mask_f))\n",
        "\n",
        "#     # Sanity check\n",
        "#     if x.shape != y.shape or x.shape[1:] != (64, 64):\n",
        "#         print(f\"Skipping mismatched: {img_f}, {mask_f}, shape: {x.shape}, {y.shape}\")\n",
        "#         continue\n",
        "\n",
        "#     X.append(x)\n",
        "#     Y.append(y)\n",
        "\n",
        "# # Final arrays\n",
        "# X = np.concatenate(X, axis=0).astype(np.float32).reshape(-1, 64, 64, 1)\n",
        "# Y = np.concatenate(Y, axis=0).astype(np.float32).reshape(-1, 64, 64, 1)\n",
        "\n",
        "# print(f\"✓ Loaded {X.shape[0]} patches.\")\n",
        "# print(\"X shape:\", X.shape)\n",
        "# print(\"Y shape:\", Y.shape)\n",
        "\n",
        "# # Optional: check how many positive pixels exist (tumor presence)\n",
        "# tumor_ratio = Y.sum() / np.prod(Y.shape)\n",
        "# print(f\"Tumor pixel ratio: {tumor_ratio:.4f} (should not be ~0)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMmxF_PmEllb",
        "outputId": "b5fe1908-9148-4e27-c6a4-0134e415044d"
      },
      "outputs": [],
      "source": [
        "# # Save as .npy for quick reloading\n",
        "# np.save(\"/content/final_tumor_patches1.npy\", X)\n",
        "# np.save(\"/content/final_tumor_masks1.npy\", Y)\n",
        "\n",
        "# print(\"✅ Final patch and mask arrays saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1hBHM0WHG4C",
        "outputId": "642ed7ce-08c6-4588-cb27-2c2e78f57dcf"
      },
      "outputs": [],
      "source": [
        "# X = np.load(\"/content/final_tumor_patches1.npy\")\n",
        "# Y = np.load(\"/content/final_tumor_masks1.npy\")\n",
        "\n",
        "# print(\"✅ Loaded saved training data:\", X.shape, Y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "s_zWGzNSaRpy",
        "outputId": "e56f5eac-70a9-491a-bd2c-c779f80bc618"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "save_dir = \"/content/patches/\"\n",
        "\n",
        "# Get all saved patch files\n",
        "patch_files = sorted([f for f in os.listdir(save_dir) if f.startswith(\"img_patches_\")])\n",
        "mask_files = sorted([f for f in os.listdir(save_dir) if f.startswith(\"mask_patches_\")])\n",
        "\n",
        "# Load patches and filter out any problematic files\n",
        "patch_list = []\n",
        "mask_list = []\n",
        "\n",
        "for f in patch_files:\n",
        "    data = np.load(os.path.join(save_dir, f))\n",
        "    if len(data.shape) == 3:  # Ensure it has (num_patches, H, W)\n",
        "        patch_list.append(data)\n",
        "    else:\n",
        "        print(f\"Skipping {f}, unexpected shape: {data.shape}\")\n",
        "\n",
        "for f in mask_files:\n",
        "    data = np.load(os.path.join(save_dir, f))\n",
        "    if len(data.shape) == 3:\n",
        "        mask_list.append(data)\n",
        "    else:\n",
        "        print(f\"Skipping {f}, unexpected shape: {data.shape}\")\n",
        "\n",
        "# Ensure all patches have the same shape before concatenation\n",
        "if len(patch_list) > 0 and len(mask_list) > 0:\n",
        "    total_patch = np.concatenate(patch_list, axis=0)\n",
        "    total_mask = np.concatenate(mask_list, axis=0)\n",
        "\n",
        "    # Reshape to (num_patches, 64, 64, 1) if needed\n",
        "    total_patch = total_patch.reshape((total_patch.shape[0], 64, 64, 1))\n",
        "    total_mask = total_mask.reshape((total_mask.shape[0], 64, 64, 1))\n",
        "\n",
        "    print(f\"Total patches shape: {total_patch.shape}\")\n",
        "    print(f\"Total masks shape: {total_mask.shape}\")\n",
        "else:\n",
        "    print(\"No valid patches found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz-_l9pPrxh-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "total_patch = np.array(total_patch).reshape((len(total_patch), 64, 64, 1))\n",
        "total_mask = np.array(total_mask).reshape((len(total_mask), 64, 64, 1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YECJ8lec4wz6",
        "outputId": "f58cccfd-ce34-4d07-a480-101aa7d55aa2"
      },
      "outputs": [],
      "source": [
        "mask_3D.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWPi548mrxiB"
      },
      "outputs": [],
      "source": [
        "np.save(\"total_patch21.npy\", total_patch)\n",
        "np.save(\"total_mask21.npy\", total_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6L71rZM5DUU",
        "outputId": "2e5a130a-57ec-4fb6-e38c-5f2f8aa26654"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/My Drive/Dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7G2SVz_Hg16"
      },
      "outputs": [],
      "source": [
        "import numpy as np;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SyZPw3Y0BQZ"
      },
      "outputs": [],
      "source": [
        "# total_patch=np.load(\"total_patch1.npy\")\n",
        "# total_mask=np.load(\"total_mask1.npy\")\n",
        "total_patch = np.load(\"total_patch21.npy\").astype(np.float32)\n",
        "total_mask = np.load(\"total_mask21.npy\").astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOTd9R_O0XhU",
        "outputId": "dedfb7c6-fe53-4ea6-ded6-754aea61f21a"
      },
      "outputs": [],
      "source": [
        "total_mask.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSUFQeq4rxiL"
      },
      "source": [
        "__Training__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6iziBCzLEx_"
      },
      "outputs": [],
      "source": [
        "# adam = Adam(learning_rate = 0.0001) # Changed 'lr' to 'learning_rate'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjOz9yVTpnlC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.saving import register_keras_serializable\n",
        "\n",
        "@register_keras_serializable()\n",
        "def weighted_binary_crossentropy(y_true, y_pred):\n",
        "    import tensorflow.keras.backend as K\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "    pos_weight = 0.90\n",
        "    neg_weight = 0.10\n",
        "    loss = - (y_true * K.log(y_pred) * pos_weight + (1 - y_true) * K.log(1 - y_pred) * neg_weight)\n",
        "    return K.mean(loss)\n",
        "\n",
        "smooth = 1.\n",
        "@register_keras_serializable()\n",
        "def dice_coef(y_true, y_pred):\n",
        "    import tensorflow.keras.backend as K\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Compile the model with the same loss and metrics\n",
        "adam = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=adam, loss=weighted_binary_crossentropy, metrics=[dice_coef])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJgocqjPfftL",
        "outputId": "fc592fec-98ef-4548-a23f-a974d213c16e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.fit(total_patch, total_mask, batch_size=32, epochs=100)\n",
        "\n",
        "\n",
        "#model = model.get_layer(\"model_7\")\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"final21.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"updated21.weights.h5\")  # ✅ Correct extension\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "model.save(\"finalmodel21.keras\")  # Saves architecture, weights, and optimizer state\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb_TWGPELwaI"
      },
      "outputs": [],
      "source": [
        "# model_json = model.to_json()\n",
        "# with open(\"model_json.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# # serialize weights to HDF5\n",
        "# model.save_weights(\"model_weights.h5\")\n",
        "# print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjT1QXqQHT7-"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from keras.saving import register_keras_serializable\n",
        "# import tensorflow.keras.backend as K\n",
        "\n",
        "\n",
        "# @register_keras_serializable()\n",
        "# def dice_coef(y_true, y_pred, smooth=1e-6):\n",
        "#     y_true_f = K.flatten(y_true)\n",
        "#     y_pred_f = K.flatten(y_pred)\n",
        "#     intersection = K.sum(y_true_f * y_pred_f)\n",
        "#     return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWr5DWnKHTOr"
      },
      "outputs": [],
      "source": [
        "# model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=[dice_coef])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSU3Q6-uHXZ0"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# class PatchDataGenerator(Sequence):\n",
        "#     def __init__(self, X, Y, batch_size=32, shuffle=True):\n",
        "#         self.X = X\n",
        "#         self.Y = Y\n",
        "#         self.batch_size = batch_size\n",
        "#         self.shuffle = shuffle\n",
        "#         self.indices = np.arange(len(self.X))\n",
        "#         if shuffle:\n",
        "#             np.random.shuffle(self.indices)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "#         batch_X = self.X[batch_indices]\n",
        "#         batch_Y = self.Y[batch_indices]\n",
        "#         return batch_X, batch_Y\n",
        "\n",
        "#     def on_epoch_end(self):\n",
        "#         if self.shuffle:\n",
        "#             np.random.shuffle(self.indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D41PTRqhIfA0",
        "outputId": "21b973ed-e808-4d81-96ee-1342a3dded69"
      },
      "outputs": [],
      "source": [
        "# train_gen = PatchDataGenerator(X, Y, batch_size=32)\n",
        "\n",
        "# model.fit(train_gen, epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_iBZk3ErxiV",
        "outputId": "25412153-4d3b-42e3-fe09-00914bbb2749",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Save model architecture to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_json1.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Save weights with the required \".weights.h5\" extension\n",
        "model.save_weights(\"model_weights1.weights.h5\")  # ✅ Correct extension\n",
        "print(\"Saved model weights to disk\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FPGowXGRF5ON"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4EWPM_n1xPE"
      },
      "source": [
        "## Save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgK8frrud3Mk",
        "outputId": "990ed1f8-b95d-4770-bebd-de0df6b879d0"
      },
      "outputs": [],
      "source": [
        "model.save(\"model21.keras\")  # Saves the model in TensorFlow's new format\n",
        "print(\"Saved entire model to disk\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYj7MS8l0oTP"
      },
      "outputs": [],
      "source": [
        "# model_json = model.to_json()\n",
        "# with open(\"model_json.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# # serialize weights to HDF5\n",
        "# model.save_weights(\"model_weights.h5\")\n",
        "# print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "XNGteHl-rxil",
        "outputId": "0e6ea6fd-dbf4-4751-dce9-d48421cda4a7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUtE2jBp3-er"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOqp9AWKMy9q",
        "outputId": "753ec3c6-cf0e-4d5d-f00c-d887338d85e1"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/My Drive/Dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvIvg1zA4NU-",
        "outputId": "25e6de37-bb20-49af-d030-3779f9f2cef2"
      },
      "outputs": [],
      "source": [
        "# json_file = open('model_json1.json', 'r')\n",
        "# loaded_model_json = json_file.read()\n",
        "# json_file.close()\n",
        "# loaded_model = model_from_json(loaded_model_json)\n",
        "# # load weights into new model\n",
        "# loaded_model.load_weights(\"model_weights1.weights.h5\")\n",
        "# print(\"Loaded model from disk\")\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "# Register your custom layers\n",
        "custom_objects = {\n",
        "    \"PatchExtractor\": PatchExtractor,\n",
        "    \"TransformerBlock\": TransformerBlock,\n",
        "    \"PositionalEmbedding\": PositionalEmbedding,\n",
        "    \"ReshapeToSpatial\": ReshapeToSpatial,\n",
        "    \"PatchProjection\": PatchProjection\n",
        "}\n",
        "\n",
        "# Load model architecture from JSON\n",
        "with open('model_json21.json', 'r') as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json, custom_objects=custom_objects)\n",
        "\n",
        "# Load weights\n",
        "loaded_model.load_weights(\"model_weights21.weights.h5\")\n",
        "\n",
        "print(\"✅ Loaded model with custom layers from disk\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K0_4OKhJccr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "O_vBA3VGtvL6",
        "outputId": "47a93e45-e322-4c49-f592-fde8aaea4a6f"
      },
      "outputs": [],
      "source": [
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_6telMu2lhA"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NaFNPEwPeTr"
      },
      "source": [
        "__Ex.1 : volum-25.nii __"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlF0d_BLBcUp",
        "outputId": "1232d707-335c-4f89-cc89-83836feaea20"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/My Drive/Dataset/Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10_qaqZMGakN"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dice_score_np(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
        "\n",
        "dice_scores = []  # List to store Dice scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltcx4w0srxjC"
      },
      "outputs": [],
      "source": [
        "img_ex = nib.load(img_path[10]).get_fdata()\n",
        "mask_ex = nib.load(mask_path[10]).get_fdata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv3Dq5YuBhOx"
      },
      "outputs": [],
      "source": [
        "img_path='/content/drive/My Drive/Dataset/Train/volume-9.nii'\n",
        "img_ex = nib.load(img_path).get_fdata()\n",
        "mask_path='/content/drive/My Drive/Dataset/Train/segmentation-9.nii'\n",
        "mask_ex = nib.load(mask_path).get_fdata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ja3zZagsrxjI",
        "outputId": "82ba76d4-298f-4532-9887-8b4f26c96e3b",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "limit = 0.75\n",
        "top_slices = []\n",
        "\n",
        "mask_ex[mask_ex == 1] = 0\n",
        "\n",
        "for i in range(mask_ex.shape[2]):\n",
        "    _, count = np.unique(mask_ex[:, :, i], return_counts=True)\n",
        "\n",
        "    if len(count) > 1 and count[1] > 300:\n",
        "        patch_ex = slice_to_patch(img_ex[:, :, i], patch_ratio)\n",
        "        prediction = loaded_model.predict(patch_ex)\n",
        "        prediction_mask = patch_to_slice(prediction, patch_ratio, input_shape, conf_threshold=0.98)\n",
        "\n",
        "        pred_bin = (prediction_mask > 0.5).astype(np.uint8)\n",
        "        true_bin = (mask_ex[:, :, i] > 0).astype(np.uint8)\n",
        "\n",
        "        dice = dice_score_np(true_bin, pred_bin)\n",
        "\n",
        "        if dice >= limit:\n",
        "            top_slices.append({\n",
        "                'dice': dice,\n",
        "                'index': i,\n",
        "                'image': img_ex[:, :, i],\n",
        "                'true_mask': true_bin,\n",
        "                'pred_mask': pred_bin.reshape((512, 512))\n",
        "            })\n",
        "\n",
        "# Sort by Dice score in descending order\n",
        "top_slices = sorted(top_slices, key=lambda x: x['dice'], reverse=True)\n",
        "\n",
        "# Print highest Dice score if available\n",
        "if top_slices:\n",
        "    print(f\"\\n Highest Dice Score: {top_slices[0]['dice']:.4f}\\n\")\n",
        "else:\n",
        "    print(\"❌ No slices found\")\n",
        "\n",
        "# Display top 3 slices with Dice ≥ 0.79\n",
        "for idx, item in enumerate(top_slices[:3]):\n",
        "    print(f\"Top {idx+1} | Slice {item['index']} | Dice Score: {item['dice']:.4f}\")\n",
        "\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 15))\n",
        "    ax1.imshow(np.rot90(item['image'], 3), cmap='bone')\n",
        "    ax1.set_title(\"Image\", fontsize=\"x-large\")\n",
        "    ax1.grid(False)\n",
        "\n",
        "    ax2.imshow(np.rot90(item['true_mask'], 3), cmap='bone')\n",
        "    ax2.set_title(\"Mask (True)\", fontsize=\"x-large\")\n",
        "    ax2.grid(False)\n",
        "\n",
        "    ax3.imshow(np.rot90(item['pred_mask'], 3), cmap='bone')\n",
        "    ax3.set_title(f\"Mask (Pred)\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    ax3.grid(False)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyviTxlcYH43"
      },
      "source": [
        "Only Tumor overlay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZsDQ3R-NbkO"
      },
      "outputs": [],
      "source": [
        "img_ex = nib.load(img_path[10]).get_fdata()\n",
        "mask_ex = nib.load(mask_path[10]).get_fdata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gS82O38qM8O7",
        "outputId": "94983413-8373-4c7b-c119-fd3fdcd5a6d8"
      },
      "outputs": [],
      "source": [
        "limit = 0.75\n",
        "top_slices = []\n",
        "\n",
        "# Make a copy of the mask to preserve the original\n",
        "tumor_mask = mask_ex.copy()\n",
        "tumor_mask[tumor_mask == 1] = 0  # Remove liver labels (keep only tumor)\n",
        "\n",
        "for i in range(mask_ex.shape[2]):\n",
        "    _, count = np.unique(tumor_mask[:, :, i], return_counts=True)\n",
        "\n",
        "    if len(count) > 1 and count[1] > 300:\n",
        "        patch_ex = slice_to_patch(img_ex[:, :, i], patch_ratio)\n",
        "        prediction = loaded_model.predict(patch_ex)\n",
        "        prediction_mask = patch_to_slice(prediction, patch_ratio, (512, 512), conf_threshold=0.98)\n",
        "\n",
        "        pred_bin = (prediction_mask > 0.5).astype(np.uint8)\n",
        "        true_bin = (tumor_mask[:, :, i] > 0).astype(np.uint8)\n",
        "\n",
        "        dice = dice_score_np(true_bin, pred_bin)\n",
        "\n",
        "        if dice >= limit:\n",
        "            # Create HU-windowed version of the CT slice\n",
        "            ct_slice = img_ex[:, :, i]\n",
        "            liver_min, liver_max = -100, 200  # Liver window\n",
        "            hu_windowed = np.clip(ct_slice, liver_min, liver_max)\n",
        "            hu_windowed = (hu_windowed - liver_min) / (liver_max - liver_min)\n",
        "\n",
        "            top_slices.append({\n",
        "                'dice': dice,\n",
        "                'index': i,\n",
        "                'image': ct_slice,\n",
        "                'hu_windowed': hu_windowed,\n",
        "                'true_mask': true_bin,\n",
        "                'pred_mask': pred_bin.reshape((512, 512))\n",
        "            })\n",
        "\n",
        "# Sort by Dice score in descending order\n",
        "top_slices = sorted(top_slices, key=lambda x: x['dice'], reverse=True)\n",
        "\n",
        "# Print highest Dice score if available\n",
        "if top_slices:\n",
        "    print(f\"\\n Highest Dice Score: {top_slices[0]['dice']:.4f}\\n\")\n",
        "else:\n",
        "    print(\"❌ No slices found\")\n",
        "\n",
        "# Display top 3 slices with Dice ≥ limit\n",
        "for idx, item in enumerate(top_slices[:3]):\n",
        "    print(f\"Top {idx+1} | Slice {item['index']} | Dice Score: {item['dice']:.4f}\")\n",
        "\n",
        "    # Create a 1x4 grid for all visualizations\n",
        "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "    # Original CT image\n",
        "    ax1.imshow(np.rot90(item['image'], 3), cmap='bone')\n",
        "    ax1.set_title(\"Original CT\", fontsize=\"x-large\")\n",
        "    ax1.grid(False)\n",
        "\n",
        "    # HU-windowed CT\n",
        "    ax2.imshow(np.rot90(item['hu_windowed'], 3), cmap='gray')\n",
        "    ax2.set_title(\"HU-Windowed CT\", fontsize=\"x-large\")\n",
        "    ax2.grid(False)\n",
        "\n",
        "    # True tumor mask\n",
        "    ax3.imshow(np.rot90(item['true_mask'], 3), cmap='bone')\n",
        "    ax3.set_title(\"Mask (True)\", fontsize=\"x-large\")\n",
        "    ax3.grid(False)\n",
        "\n",
        "    # Predicted tumor mask\n",
        "    ax4.imshow(np.rot90(item['pred_mask'], 3), cmap='bone')\n",
        "    ax4.set_title(f\"Mask (Pred)\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    ax4.grid(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Add a second visualization showing the tumor overlay on the HU-windowed CT\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "    # Create a colored version of the HU-windowed CT image\n",
        "    overlay = np.stack([item['hu_windowed'], item['hu_windowed'], item['hu_windowed']], axis=2)\n",
        "\n",
        "    # Highlight tumor prediction in red\n",
        "    tumor_pixels = item['pred_mask'].astype(bool)\n",
        "    overlay[tumor_pixels] = [1.0, 0.3, 0.3]  # Red for tumor\n",
        "\n",
        "    # Display the overlay\n",
        "    ax.imshow(np.rot90(overlay, 3))\n",
        "    ax.set_title(f\"Tumor Overlay on HU-Windowed CT\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    ax.grid(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z2j_0Hp8NvaR",
        "outputId": "5e04af24-44e2-41c0-f631-19e0d6aa0174"
      },
      "outputs": [],
      "source": [
        "limit = 0.75\n",
        "top_slices = []\n",
        "\n",
        "# Make a copy of the mask to preserve the original\n",
        "tumor_mask = mask_ex.copy()\n",
        "tumor_mask[tumor_mask == 1] = 0  # Remove liver labels (keep only tumor)\n",
        "\n",
        "for i in range(mask_ex.shape[2]):\n",
        "    _, count = np.unique(tumor_mask[:, :, i], return_counts=True)\n",
        "\n",
        "    if len(count) > 1 and count[1] > 300:\n",
        "        patch_ex = slice_to_patch(img_ex[:, :, i], patch_ratio)\n",
        "        prediction = loaded_model.predict(patch_ex)\n",
        "        prediction_mask = patch_to_slice(prediction, patch_ratio, (512, 512), conf_threshold=0.98)\n",
        "\n",
        "        pred_bin = (prediction_mask > 0.5).astype(np.uint8)\n",
        "        true_bin = (tumor_mask[:, :, i] > 0).astype(np.uint8)\n",
        "\n",
        "        dice = dice_score_np(true_bin, pred_bin)\n",
        "\n",
        "        if dice >= limit:\n",
        "            # Create HU-windowed version of the CT slice\n",
        "            ct_slice = img_ex[:, :, i]\n",
        "            liver_min, liver_max = -100, 200  # Liver window\n",
        "            hu_windowed = np.clip(ct_slice, liver_min, liver_max)\n",
        "            hu_windowed = (hu_windowed - liver_min) / (liver_max - liver_min)\n",
        "\n",
        "            # Get the liver mask from the original mask (assuming 1 is liver)\n",
        "            liver_mask = (mask_ex[:, :, i] == 1).astype(np.uint8)\n",
        "\n",
        "            top_slices.append({\n",
        "                'dice': dice,\n",
        "                'index': i,\n",
        "                'image': ct_slice,\n",
        "                'hu_windowed': hu_windowed,\n",
        "                'true_mask': true_bin,\n",
        "                'liver_mask': liver_mask,\n",
        "                'pred_mask': pred_bin.reshape((512, 512))\n",
        "            })\n",
        "\n",
        "# Sort by Dice score in descending order\n",
        "top_slices = sorted(top_slices, key=lambda x: x['dice'], reverse=True)\n",
        "\n",
        "# Print highest Dice score if available\n",
        "if top_slices:\n",
        "    print(f\"\\n Highest Dice Score: {top_slices[0]['dice']:.4f}\\n\")\n",
        "else:\n",
        "    print(\"❌ No slices found\")\n",
        "\n",
        "# Display top 3 slices with Dice ≥ limit\n",
        "for idx, item in enumerate(top_slices[:3]):\n",
        "    print(f\"Top {idx+1} | Slice {item['index']} | Dice Score: {item['dice']:.4f}\")\n",
        "\n",
        "    # Create a 1x4 grid for all visualizations\n",
        "    # fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "    # # Original CT image\n",
        "    # ax1.imshow(np.rot90(item['image'], 3), cmap='bone')\n",
        "    # ax1.set_title(\"Original CT\", fontsize=\"x-large\")\n",
        "    # ax1.grid(False)\n",
        "\n",
        "    # # HU-windowed CT\n",
        "    # ax2.imshow(np.rot90(item['hu_windowed'], 3), cmap='gray')\n",
        "    # ax2.set_title(\"HU-Windowed CT\", fontsize=\"x-large\")\n",
        "    # ax2.grid(False)\n",
        "\n",
        "    # # True tumor mask\n",
        "    # ax3.imshow(np.rot90(item['true_mask'], 3), cmap='bone')\n",
        "    # ax3.set_title(\"Mask (True)\", fontsize=\"x-large\")\n",
        "    # ax3.grid(False)\n",
        "\n",
        "    # # Predicted tumor mask\n",
        "    # ax4.imshow(np.rot90(item['pred_mask'], 3), cmap='bone')\n",
        "    # ax4.set_title(f\"Mask (Pred)\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    # ax4.grid(False)\n",
        "\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    # # Add a visualization showing both liver and tumor overlay on the HU-windowed CT\n",
        "    # fig, ax = plt.subplots(figsize=(16, 4))  # Match with above\n",
        "\n",
        "    # # Create a colored version of the HU-windowed CT image\n",
        "    # overlay = np.stack([item['hu_windowed'], item['hu_windowed'], item['hu_windowed']], axis=2)\n",
        "\n",
        "    # # Highlight liver in blue (semi-transparent) - use valid color values (0-1)\n",
        "    # liver_pixels = item['liver_mask'].astype(bool)\n",
        "    # # Use multiplication factor that keeps values within 0-1 range\n",
        "    # overlay[liver_pixels] = overlay[liver_pixels] * [0.7, 0.7, 1.0]  # Blue tint for liver (safe values)\n",
        "\n",
        "    # # Highlight tumor prediction in red (more prominent)\n",
        "    # tumor_pixels = item['pred_mask'].astype(bool)\n",
        "    # overlay[tumor_pixels] = [1.0, 0.3, 0.3]  # Red for tumor\n",
        "\n",
        "    # # Display the overlay with rotation\n",
        "    # ax.imshow(np.rot90(overlay, 3))\n",
        "    # ax.set_title(f\"Liver & Tumor Overlay on HU-Windowed CT\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    # ax.grid(False)\n",
        "\n",
        "    # # Add a legend with valid color values\n",
        "    # from matplotlib.patches import Patch\n",
        "    # legend_elements = [\n",
        "    #     Patch(facecolor=[0.7, 0.7, 1.0], label='Liver'),  # Fixed: 1.2 -> 1.0\n",
        "    #     Patch(facecolor=[1.0, 0.3, 0.3], label='Tumor (Pred)')\n",
        "    # ]\n",
        "    # ax.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 4))  # <- updated size\n",
        "\n",
        "    # Original CT image\n",
        "    ax1.imshow(np.rot90(item['image'], 3), cmap='bone')\n",
        "    ax1.set_title(\"Original CT\", fontsize=\"large\")\n",
        "    ax1.grid(False)\n",
        "\n",
        "    # HU-windowed CT\n",
        "    ax2.imshow(np.rot90(item['hu_windowed'], 3), cmap='gray')\n",
        "    ax2.set_title(\"HU-Windowed CT\", fontsize=\"large\")\n",
        "    ax2.grid(False)\n",
        "\n",
        "    # True tumor mask\n",
        "    ax3.imshow(np.rot90(item['true_mask'], 3), cmap='bone')\n",
        "    ax3.set_title(\"Mask (True)\", fontsize=\"large\")\n",
        "    ax3.grid(False)\n",
        "\n",
        "    # Predicted tumor mask\n",
        "    ax4.imshow(np.rot90(item['pred_mask'], 3), cmap='bone')\n",
        "    ax4.set_title(f\"Mask (Pred)\\nDice: {item['dice']:.4f}\", fontsize=\"large\")\n",
        "    ax4.grid(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Create consistent overlay visualization (same width and height)\n",
        "    fig, ax = plt.subplots(figsize=(16, 4))  # <- match size\n",
        "\n",
        "    # Create color overlay\n",
        "    overlay = np.stack([item['hu_windowed']] * 3, axis=2)\n",
        "\n",
        "    # Apply liver (blue) overlay\n",
        "    liver_pixels = item['liver_mask'].astype(bool)\n",
        "    overlay[liver_pixels] = overlay[liver_pixels] * [0.7, 0.7, 1.0]\n",
        "\n",
        "    # Apply tumor prediction (red)\n",
        "    tumor_pixels = item['pred_mask'].astype(bool)\n",
        "    overlay[tumor_pixels] = [1.0, 0.3, 0.3]\n",
        "\n",
        "    # Show image\n",
        "    ax.imshow(np.rot90(overlay, 3))\n",
        "    ax.set_title(f\"Liver & Tumor Overlay on HU-Windowed CT\\nDice: {item['dice']:.4f}\", fontsize=\"large\")\n",
        "    ax.grid(False)\n",
        "\n",
        "    # Legend\n",
        "    from matplotlib.patches import Patch\n",
        "    legend_elements = [\n",
        "        Patch(facecolor=[0.7, 0.7, 1.0], label='Liver'),\n",
        "        Patch(facecolor=[1.0, 0.3, 0.3], label='Tumor (Pred)')\n",
        "    ]\n",
        "    ax.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlwJIr6KRFPA"
      },
      "outputs": [],
      "source": [
        "img_ex = nib.load(img_path[10]).get_fdata()\n",
        "mask_ex = nib.load(mask_path[10]).get_fdata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "67a5rPQtQ0h3",
        "outputId": "44d1284f-deba-4b86-f367-1d241e4b296d"
      },
      "outputs": [],
      "source": [
        "limit = 0.75\n",
        "top_slices = []\n",
        "\n",
        "# Make a copy of the mask to preserve the original\n",
        "tumor_mask = mask_ex.copy()\n",
        "tumor_mask[tumor_mask == 1] = 0  # Remove liver labels (keep only tumor)\n",
        "\n",
        "for i in range(mask_ex.shape[2]):\n",
        "    _, count = np.unique(tumor_mask[:, :, i], return_counts=True)\n",
        "\n",
        "    if len(count) > 1 and count[1] > 300:\n",
        "        patch_ex = slice_to_patch(img_ex[:, :, i], patch_ratio)\n",
        "        prediction = loaded_model.predict(patch_ex)\n",
        "        prediction_mask = patch_to_slice(prediction, patch_ratio, (512, 512), conf_threshold=0.98)\n",
        "\n",
        "        pred_bin = (prediction_mask > 0.5).astype(np.uint8)\n",
        "        true_bin = (tumor_mask[:, :, i] > 0).astype(np.uint8)\n",
        "\n",
        "        dice = dice_score_np(true_bin, pred_bin)\n",
        "\n",
        "        if dice >= limit:\n",
        "            # Create HU-windowed version of the CT slice\n",
        "            ct_slice = img_ex[:, :, i]\n",
        "            liver_min, liver_max = -100, 200  # Liver window\n",
        "            hu_windowed = np.clip(ct_slice, liver_min, liver_max)\n",
        "            hu_windowed = (hu_windowed - liver_min) / (liver_max - liver_min)\n",
        "\n",
        "            # Get the liver mask from the original mask (assuming 1 is liver)\n",
        "            liver_mask = (mask_ex[:, :, i] == 1).astype(np.uint8)\n",
        "\n",
        "            # Get tumor mask from original mask (assuming values > 1 are tumor)\n",
        "            true_tumor_mask = true_bin\n",
        "\n",
        "            top_slices.append({\n",
        "                'dice': dice,\n",
        "                'index': i,\n",
        "                'image': ct_slice,\n",
        "                'hu_windowed': hu_windowed,\n",
        "                'liver_mask': liver_mask,\n",
        "                'true_tumor_mask': true_tumor_mask,\n",
        "                'pred_mask': pred_bin.reshape((512, 512))\n",
        "            })\n",
        "\n",
        "# Sort by Dice score in descending order\n",
        "top_slices = sorted(top_slices, key=lambda x: x['dice'], reverse=True)\n",
        "\n",
        "# Print highest Dice score if available\n",
        "if top_slices:\n",
        "    print(f\"\\n Highest Dice Score: {top_slices[0]['dice']:.4f}\\n\")\n",
        "else:\n",
        "    print(\"❌ No slices found\")\n",
        "\n",
        "# Display top 3 slices with Dice ≥ limit\n",
        "for idx, item in enumerate(top_slices[:3]):\n",
        "    print(f\"Top {idx+1} | Slice {item['index']} | Dice Score: {item['dice']:.4f}\")\n",
        "\n",
        "    # Create a 1x3 grid for main visualizations\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Original CT image\n",
        "    ax1.imshow(np.rot90(item['image'], 3), cmap='bone')\n",
        "    ax1.set_title(\"Original CT\", fontsize=\"x-large\")\n",
        "    ax1.grid(False)\n",
        "\n",
        "    # HU-windowed CT\n",
        "    ax2.imshow(np.rot90(item['hu_windowed'], 3), cmap='gray')\n",
        "    ax2.set_title(\"HU-Windowed CT\", fontsize=\"x-large\")\n",
        "    ax2.grid(False)\n",
        "\n",
        "    # Predicted tumor mask\n",
        "    ax3.imshow(np.rot90(item['pred_mask'], 3), cmap='bone')\n",
        "    ax3.set_title(f\"Tumor Mask (Pred)\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    ax3.grid(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Add a visualization showing ground truth liver and tumor overlay on the HU-windowed CT\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    # 1. Ground Truth Overlay\n",
        "    # Create a colored version of the HU-windowed CT image\n",
        "    gt_overlay = np.stack([item['hu_windowed'], item['hu_windowed'], item['hu_windowed']], axis=2)\n",
        "\n",
        "    # Highlight ground truth liver in blue\n",
        "    liver_pixels = item['liver_mask'].astype(bool)\n",
        "    gt_overlay[liver_pixels] = gt_overlay[liver_pixels] * [0.7, 0.7, 1.0]  # Blue tint for liver\n",
        "\n",
        "    # Highlight ground truth tumor in red\n",
        "    true_tumor_pixels = item['true_tumor_mask'].astype(bool)\n",
        "    gt_overlay[true_tumor_pixels] = [1.0, 0.3, 0.3]  # Red for tumor\n",
        "\n",
        "    # Display the ground truth overlay with rotation\n",
        "    ax1.imshow(np.rot90(gt_overlay, 3))\n",
        "    ax1.set_title(\"Ground Truth: Liver (Blue) & Tumor (Red)\", fontsize=\"x-large\")\n",
        "    ax1.grid(False)\n",
        "\n",
        "    # 2. Prediction Overlay\n",
        "    # Create a colored version of the HU-windowed CT image\n",
        "    pred_overlay = np.stack([item['hu_windowed'], item['hu_windowed'], item['hu_windowed']], axis=2)\n",
        "\n",
        "    # Highlight ground truth liver in blue (same as in ground truth)\n",
        "    pred_overlay[liver_pixels] = pred_overlay[liver_pixels] * [0.7, 0.7, 1.0]  # Blue tint for liver\n",
        "\n",
        "    # Highlight predicted tumor in red\n",
        "    pred_tumor_pixels = item['pred_mask'].astype(bool)\n",
        "    pred_overlay[pred_tumor_pixels] = [1.0, 0.3, 0.3]  # Red for tumor\n",
        "\n",
        "    # Display the prediction overlay with rotation\n",
        "    ax2.imshow(np.rot90(pred_overlay, 3))\n",
        "    ax2.set_title(f\"Prediction: Liver (Blue) & Tumor (Red)\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    ax2.grid(False)\n",
        "\n",
        "    # Add a legend with valid color values\n",
        "    from matplotlib.patches import Patch\n",
        "    legend_elements = [\n",
        "        Patch(facecolor=[0.7, 0.7, 1.0], label='Liver'),\n",
        "        Patch(facecolor=[1.0, 0.3, 0.3], label='Tumor')\n",
        "    ]\n",
        "    ax1.legend(handles=legend_elements, loc='lower right')\n",
        "    ax2.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cbxTn0BRVADh",
        "outputId": "86d22cda-aa27-4799-9b93-3cdcf364144f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# --- Helper: HU Normalization ---\n",
        "def normalize_hu(volume, clip_min=-100, clip_max=400):\n",
        "    volume = np.clip(volume, clip_min, clip_max)\n",
        "    return (volume - clip_min) / (clip_max - clip_min)\n",
        "\n",
        "# --- Evaluate Model & Visualize Top Tumor Predictions ---\n",
        "limit = 0.75\n",
        "top_slices = []\n",
        "\n",
        "# Remove liver label (keep only tumor)\n",
        "tumor_mask = mask_ex.copy()\n",
        "tumor_mask[tumor_mask == 1] = 0  # Remove liver\n",
        "tumor_mask[tumor_mask == 2] = 1  # Tumor = 1\n",
        "\n",
        "for i in range(mask_ex.shape[2]):\n",
        "    _, count = np.unique(tumor_mask[:, :, i], return_counts=True)\n",
        "\n",
        "    if len(count) > 1 and count[1] > 300:  # Tumor present\n",
        "        patch_ex = slice_to_patch(img_ex[:, :, i], patch_ratio)\n",
        "        prediction = loaded_model.predict(patch_ex)\n",
        "        prediction_mask = patch_to_slice(prediction, patch_ratio, (512, 512), conf_threshold=0.98)\n",
        "\n",
        "        pred_bin = (prediction_mask > 0.5).astype(np.uint8)\n",
        "        true_bin = (tumor_mask[:, :, i] > 0).astype(np.uint8)\n",
        "\n",
        "        dice = dice_score_np(true_bin, pred_bin)\n",
        "\n",
        "        if dice >= limit:\n",
        "            ct_slice = img_ex[:, :, i]  # Raw HU values\n",
        "            hu_windowed = normalize_hu(ct_slice)  # ✅ HU-normalized\n",
        "\n",
        "            liver_mask = (mask_ex[:, :, i] == 1).astype(np.uint8)\n",
        "            true_tumor_mask = true_bin\n",
        "\n",
        "            top_slices.append({\n",
        "                'dice': dice,\n",
        "                'index': i,\n",
        "                'image': ct_slice,\n",
        "                'hu_windowed': hu_windowed,\n",
        "                'liver_mask': liver_mask,\n",
        "                'true_tumor_mask': true_tumor_mask,\n",
        "                'pred_mask': pred_bin.reshape((512, 512))\n",
        "            })\n",
        "\n",
        "# --- Sort by Dice ---\n",
        "top_slices = sorted(top_slices, key=lambda x: x['dice'], reverse=True)\n",
        "\n",
        "# --- Print Best Dice ---\n",
        "if top_slices:\n",
        "    print(f\"\\n Highest Dice Score: {top_slices[0]['dice']:.4f}\\n\")\n",
        "else:\n",
        "    print(\"❌ No slices found\")\n",
        "\n",
        "# --- Visualize Top 3 Slices ---\n",
        "for idx, item in enumerate(top_slices[:3]):\n",
        "    print(f\"Top {idx+1} | Slice {item['index']} | Dice Score: {item['dice']:.4f}\")\n",
        "\n",
        "    # --- Main Views: CT, HU-windowed, Pred ---\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    ax1.imshow(np.rot90(item['image'], 3), cmap='bone')\n",
        "    ax1.set_title(\"Original CT\", fontsize=\"x-large\")\n",
        "    ax1.grid(False)\n",
        "\n",
        "    ax2.imshow(np.rot90(item['hu_windowed'], 3), cmap='gray')\n",
        "    ax2.set_title(\"HU-Normalized CT\", fontsize=\"x-large\")\n",
        "    ax2.grid(False)\n",
        "\n",
        "    ax3.imshow(np.rot90(item['pred_mask'], 3), cmap='bone')\n",
        "    ax3.set_title(f\"Tumor Prediction\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    ax3.grid(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Overlays: Ground Truth and Prediction ---\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    hu_rgb = np.stack([item['hu_windowed']] * 3, axis=2)\n",
        "\n",
        "    # --- Ground Truth Overlay ---\n",
        "    gt_overlay = hu_rgb.copy()\n",
        "    gt_overlay[item['liver_mask'].astype(bool)] *= [0.7, 0.7, 1.0]  # Blue for liver\n",
        "    gt_overlay[item['true_tumor_mask'].astype(bool)] = [1.0, 0.3, 0.3]  # Red for tumor\n",
        "\n",
        "    ax1.imshow(np.rot90(gt_overlay, 3))\n",
        "    ax1.set_title(\"Ground Truth: Liver (Blue), Tumor (Red)\", fontsize=\"x-large\")\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # --- Prediction Overlay ---\n",
        "    pred_overlay = hu_rgb.copy()\n",
        "    pred_overlay[item['liver_mask'].astype(bool)] *= [0.7, 0.7, 1.0]\n",
        "    pred_overlay[item['pred_mask'].astype(bool)] = [1.0, 0.3, 0.3]\n",
        "\n",
        "    ax2.imshow(np.rot90(pred_overlay, 3))\n",
        "    ax2.set_title(f\"Prediction: Liver (Blue), Tumor (Red)\\nDice: {item['dice']:.4f}\", fontsize=\"x-large\")\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # --- Legend ---\n",
        "    legend_elements = [\n",
        "        Patch(facecolor=[0.7, 0.7, 1.0], label='Liver'),\n",
        "        Patch(facecolor=[1.0, 0.3, 0.3], label='Tumor')\n",
        "    ]\n",
        "    ax1.legend(handles=legend_elements, loc='lower right')\n",
        "    ax2.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "63u7DYDCB8wD",
        "outputId": "2e9b5bdb-4642-411b-cc90-52b967efaae7"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "# Assume files are already in a local directory (modify this for your environment)\n",
        "# These should be NIfTI files from LiTS challenge\n",
        "image_paths = sorted(glob(\"volume-*.nii\"))  # Load only one for demo\n",
        "mask_paths = sorted(glob(\"segmentation-*.nii\"))\n",
        "\n",
        "# Load the first volume and mask\n",
        "img = nib.load(image_paths[10]).get_fdata()\n",
        "mask = nib.load(mask_paths[10]).get_fdata()\n",
        "\n",
        "# Extract HU values based on mask labels\n",
        "liver_voxels = img[mask == 1]\n",
        "tumor_voxels = img[mask == 2]\n",
        "\n",
        "# Basic stats\n",
        "liver_mean, liver_std = np.mean(liver_voxels), np.std(liver_voxels)\n",
        "tumor_mean, tumor_std = np.mean(tumor_voxels), np.std(tumor_voxels)\n",
        "\n",
        "# Plot real histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(liver_voxels, bins=60, alpha=0.6, label=f'Liver (mean={liver_mean:.1f})', color='blue', density=True)\n",
        "plt.hist(tumor_voxels, bins=60, alpha=0.6, label=f'Tumor (mean={tumor_mean:.1f})', color='red', density=True)\n",
        "plt.axvline(liver_mean, color='blue', linestyle='--')\n",
        "plt.axvline(tumor_mean, color='red', linestyle='--')\n",
        "plt.title(\"Real HU Distributions from LiTS Volume\", fontsize=14)\n",
        "plt.xlabel(\"Hounsfield Unit (HU)\")\n",
        "plt.ylabel(\"Normalized Frequency\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg8vsOMCBi5w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BXkpllrBjwn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhVFyEGvPrfu"
      },
      "source": [
        "__Ex.2 : volum-129.nii __"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCvrkOQ8rxi7"
      },
      "outputs": [],
      "source": [
        "# img_ex = nib.load(img_path[54]).get_fdata()\n",
        "# mask_ex = nib.load(mask_path[54]).get_fdata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnqlUO7Drxi9",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# mask_ex[mask_ex == 1] = 0\n",
        "\n",
        "# for i in range(mask_ex.shape[2]):\n",
        "#     _, count = np.unique(mask_ex[:, :, i], return_counts=True)\n",
        "\n",
        "#     if len(count) > 1 and count[1] > 300:\n",
        "\n",
        "#         patch_ex = slice_to_patch(img_ex[:, :, i], patch_ratio)\n",
        "#         prediction = loaded_model.predict(patch_ex)\n",
        "#         prediction_mask = patch_to_slice(prediction, patch_ratio, input_shape, conf_threshold = 0.98)\n",
        "\n",
        "#         fig, (ax1,ax2,ax3) = plt.subplots(1, 3, figsize = ((15, 15)))\n",
        "\n",
        "#         ax1.imshow(np.rot90(img_ex[:, :, i], 3), cmap = 'bone')\n",
        "#         ax1.set_title(\"Image\", fontsize = \"x-large\")\n",
        "#         ax1.grid(False)\n",
        "#         ax2.imshow(np.rot90(mask_ex[:, :, i], 3), cmap = 'bone')\n",
        "#         ax2.set_title(\"Mask (True)\", fontsize = \"x-large\")\n",
        "#         ax2.grid(False)\n",
        "#         ax3.imshow(np.rot90(prediction_mask.reshape((512, 512)), 3), cmap = 'bone')\n",
        "#         ax3.set_title(\"Mask (Pred)\", fontsize = \"x-large\")\n",
        "#         ax3.grid(False)\n",
        "#         plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYncZvSjPuWO"
      },
      "source": [
        "__Ex.3 : volum-27.nii __"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koHIxjJ92xCq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "KzYvx1L1rxi2",
        "outputId": "edebfbb6-9cc4-4b21-a9fd-8cbe8fd6c11c",
        "scrolled": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppIae0JNNDV3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzZKuN3qHO5t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOVlbne1NDMU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1jusaSrnTrE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLeMnz-inZ3o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1v8WpScaj-v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve-MY-fVnYtu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbSqW5b-nhTY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N26KyREOSxM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ADgtR_hObmg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dELByt4VO7er"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNayJKwxOePU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUMaaWf_Olyu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRlc7Uk-c3j6"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p49kv-c_Op-O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leYy_nFadQY0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
